{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2g1jzbRgwwQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Download library\n",
        "!pip install diffusers==0.21.4 datasets wandb accelerate gradio\n",
        "!pip install -U huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load library\n",
        "from huggingface_hub import HfApi, ModelCard, create_repo, get_full_repo_name\n",
        "from diffusers import DDIMScheduler, DDIMPipeline\n",
        "from torchvision import transforms\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import accelerate\n",
        "import torch\n",
        "import wandb\n",
        "import time\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "eseM3TChvyGb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load need library\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"): RunningInCOLAB = True\n",
        "else: RunningInCOLAB = False\n",
        "\n",
        "not_wandb = False\n",
        "hf_success = False\n",
        "\n",
        "def future_update():\n",
        "  update = gr.Markdown(\"\"\"\n",
        "                      # This page can't work\n",
        "                      Now this page can't work. Please wait future update.\n",
        "                      \"\"\")\n",
        "  return update\n",
        "\n",
        "def image_crop(image):\n",
        "  width, height = image.size\n",
        "  save = []\n",
        "  for w in range(width//(width//2)):\n",
        "    for h in range(height//(height//2)):\n",
        "      box = (w*(width//2), h*(height//2), (w+1)*(width//2), (h+1)*(height//2))\n",
        "      save.append(image.crop(box))\n",
        "  return save\n",
        "\n",
        "def pushhub(model, model_name, model_description):\n",
        "  model.save_pretrained(\"my_pipeline\")\n",
        "  hub_model_id = get_full_repo_name(model_name)\n",
        "  try: create_repo(hub_model_id)\n",
        "  except: pass\n",
        "  api = HfApi()\n",
        "  api.upload_folder(folder_path=\"my_pipeline/scheduler\", path_in_repo=\"scheduler/\", repo_id=hub_model_id)\n",
        "  api.upload_folder(folder_path=\"my_pipeline/unet\", path_in_repo=\"unet/\", repo_id=hub_model_id)\n",
        "  api.upload_file(path_or_fileobj=\"my_pipeline/model_index.json\", path_in_repo=\"model_index.json\",repo_id=hub_model_id)\n",
        "  card = ModelCard(model_description)\n",
        "  card.push_to_hub(hub_model_id)\n",
        "\n",
        "def show_images(x):\n",
        "  grid = torchvision.utils.make_grid(x, nrow=2, padding=0)\n",
        "  grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255\n",
        "  grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))\n",
        "  return grid_im\n",
        "\n",
        "def image_generate(ch_num, scheduler, pretrained_pipeline, image_size):\n",
        "  image_size = tuple(map(int, image_size.replace('(', '').replace(')', '').split(',')))\n",
        "  x = torch.randn(4, ch_num, *image_size).to(device)\n",
        "  for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "    model_input = scheduler.scale_model_input(x, t)\n",
        "    with torch.no_grad():\n",
        "      noise_pred = pretrained_pipeline.unet(model_input, t)[\"sample\"]\n",
        "    x = scheduler.step(noise_pred, t, x).prev_sample\n",
        "  return show_images(x)\n",
        "\n",
        "def hf_login(huggingface_write_token, huggingface_secret_token):\n",
        "  global hf_success\n",
        "  if not huggingface_write_token and not huggingface_secret_token: raise gr.Error('Please write Huggingface access token with write permission')\n",
        "  else:\n",
        "    try:\n",
        "      gr.Info('Try login in HuggingFace')\n",
        "      if RunningInCOLAB == True:\n",
        "        from google.colab import userdata\n",
        "        login(token=userdata.get(huggingface_secret_token), add_to_git_credential=True)\n",
        "      else: login(token=huggingface_write_token, add_to_git_credential=True)\n",
        "      time.sleep(5)\n",
        "      hf_success = True\n",
        "      gr.Info('Login success')\n",
        "    except Exception as e: gr.Error(e)\n",
        "\n",
        "def wandb_setup(wandb_write_token, wandb_secret_token, wandb_project_name, wandb_run_name):\n",
        "  global not_wandb\n",
        "  if hf_success == False: raise gr.Warning('Please login in HuggingFace before starting other code')\n",
        "\n",
        "  if not wandb_write_token and not wandb_secret_token:\n",
        "    not_wandb = True\n",
        "    raise gr.Error('Please write WanDB api token')\n",
        "\n",
        "  else:\n",
        "    gr.Info('Start setup WanDB')\n",
        "    if RunningInCOLAB:\n",
        "      from google.colab import userdata\n",
        "      wandb.login(key=userdata.get(wandb_secret_token))\n",
        "    else: wandb.login(key=wandb_write_token)\n",
        "\n",
        "    if not wandb_project_name: raise gr.Error('Please write wandb project name')\n",
        "    elif not wandb_run_name:\n",
        "      gr.Info(\"Wandb run name not choose. Using random name\")\n",
        "      wandb.init(project=wandb_project_name)\n",
        "    else: wandb.init(project=wandb_project_name, name=wandb_run_name)\n",
        "    time.sleep(5)\n",
        "    gr.Info('WanDB setup success')\n",
        "\n",
        "def start_setup(pretrained_model, dataset_name, image_size, batch_size, color_value, epoch, grad_accumulation_steps, save_to_hub, image_example, model_name, model_description):\n",
        "  if hf_success == False: raise gr.Warning('Please login in HuggingFace before starting other code')\n",
        "\n",
        "  if not re.search(r'^[A-Za-z0-9/-]+/[A-Za-z0-9/-]+$', pretrained_model): raise gr.Error('Please write link of pretrained model')\n",
        "  else:\n",
        "    gr.Info(\"Try to load pretrained model\")\n",
        "    try: pretrained_pipeline = DDIMPipeline.from_pretrained(pretrained_model).to(device)\n",
        "    except Exception as e: raise gr.Error(e)\n",
        "  time.sleep(5)\n",
        "\n",
        "  if not re.search(r'^[A-Za-z0-9_-]+/[A-Za-z0-9_-]+$', dataset_name): raise gr.Error('Please write link of dataset')\n",
        "  else:\n",
        "    gr.Info(\"Try to load dataset\")\n",
        "    try: dataset = load_dataset(dataset_name, split=\"train\")\n",
        "    except Exception as e: raise gr.Error(e)\n",
        "  time.sleep(5)\n",
        "\n",
        "  if not re.search(r'^\\(\\d+,\\s*\\d+\\)$', image_size): raise gr.Error('Please write image size: or check correct form of \"image size\" value')\n",
        "  else:\n",
        "    try: preprocess = transforms.Compose([transforms.Resize(eval(image_size)), transforms.ToTensor(),])\n",
        "    except Exception as e: raise gr.Error(e)\n",
        "\n",
        "  if not batch_size or batch_size <= 0: raise gr.Error('Please write batch size or check correct form of \"batch size\" value') #re.search(r'^\\d+$', batch_size)\n",
        "  time.sleep(5)\n",
        "\n",
        "  if not color_value: raise gr.Error('Please write what type of image use: RGBA, RGB')\n",
        "  else:\n",
        "    try:\n",
        "      def transform(examples):\n",
        "        images = [preprocess(image.convert(color_value)) for image in examples[\"image\"]]\n",
        "        return {\"images\": images}\n",
        "      dataset.set_transform(transform)\n",
        "      ch_num = (3 if color_value == 'RGB' else 4)\n",
        "      train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    except Exception as e: raise gr.Error(e)\n",
        "  time.sleep(5)\n",
        "\n",
        "  gr.Info('Load training setting')\n",
        "  if epoch <= 0 or not epoch: raise gr.Error('Please write count of training epoch')\n",
        "  if grad_accumulation_steps < 0 or not grad_accumulation_steps: raise gr.Error('Please write count of gradient accumulation step: Minimum = 0')\n",
        "  if save_to_hub < 0 or not save_to_hub: raise gr.Error('Please write what number of epoch need to push checkpoint in hub: Minimum = 0')\n",
        "  if image_example < 0 or not image_example: raise gr.Error('Please write what number of epoch need to save image example: Minimum = 0')\n",
        "  if not model_name: raise gr.Error('Please write model name to push in hub')\n",
        "  if not model_description:\n",
        "    model_description = f\"\"\"\n",
        "    ---\n",
        "    license: mit\n",
        "    tags:\n",
        "    - pytorch\n",
        "    - diffusers\n",
        "    - unconditional-image-generation\n",
        "    - diffusion-model\n",
        "    ---\n",
        "    \"\"\"\n",
        "\n",
        "  try: scheduler = DDIMScheduler.from_pretrained(pretrained_model)\n",
        "  except: scheduler = DDIMScheduler.from_pretrained(pretrained_model, subfolder='scheduler')\n",
        "  scheduler.set_timesteps(num_inference_steps=35)\n",
        "  lr = 1e-5\n",
        "  optimizer = torch.optim.AdamW(pretrained_pipeline.unet.parameters(), lr=lr)\n",
        "  losses = []\n",
        "\n",
        "  gr.Info('Start training')\n",
        "  for epoch in range(epoch):\n",
        "    gr.Info(f'Epoch: {epoch}')\n",
        "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "      clean_images = batch['images'].to(device)\n",
        "      #clean_images = batch[0].to(device)\n",
        "      noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
        "      bs = clean_images.shape[0]\n",
        "\n",
        "      timesteps = torch.randint(0, pretrained_pipeline.scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()\n",
        "      noisy_images = pretrained_pipeline.scheduler.add_noise(clean_images, noise, timesteps)\n",
        "      noise_pred = pretrained_pipeline.unet(noisy_images, timesteps, return_dict=False)[0]\n",
        "      loss = F.mse_loss(noise_pred, noise)\n",
        "      losses.append(loss.item())\n",
        "      loss.backward(loss)\n",
        "\n",
        "      if (step + 1) % grad_accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    gr.Info(f'average loss: {sum(losses[-len(train_dataloader):])/len(train_dataloader)}')\n",
        "\n",
        "    if epoch % save_to_hub == 0:\n",
        "        try: pushhub(pretrained_pipeline, model_name, model_description)\n",
        "        except Exception as e: raise gr.Error(e)\n",
        "\n",
        "    if not_wandb == False:\n",
        "      wandb.log({'Epoch loss':sum(losses[-len(train_dataloader):])/len(train_dataloader)})\n",
        "      if epoch % image_example == 0:\n",
        "        wandb.log({'Sample generations': wandb.Image(image_generate(ch_num, scheduler, pretrained_pipeline, image_size))})\n",
        "\n",
        "  return image_crop(image_generate(ch_num, scheduler, pretrained_pipeline, image_size))"
      ],
      "metadata": {
        "id": "B7KXKkDCq48W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run code\n",
        "device = (\"mps\"\n",
        "    if torch.backends.mps.is_available() else \"cuda\"\n",
        "    if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "demo = gr.Blocks(title='diffusion-model-webui')\n",
        "with demo:\n",
        "    gr.HTML(\"\"\"\n",
        "            <div style=\"display: flex; margin-bottom: 0.5%; justify-content: center;\">\n",
        "              <p style=\"font-size: 24px\"><b>diffusion-model-webui</b></p>\n",
        "             </div>\n",
        "            \"\"\"\n",
        "           )\n",
        "    with gr.Tabs():\n",
        "      with gr.TabItem(\"About\"):\n",
        "        gr.Markdown(f'''\n",
        "                    # Diffusion Model WebUI\n",
        "\n",
        "                    An educational project that is created to test my own skills and make it easier to work with the ***Diffusers*** HuggingFace library.\n",
        "                    Full code in <a href='https://github.com/WiNE-iNEFF/diffusion-model-webui'>GitHub page</a>.\n",
        "\n",
        "                    This gradio space run {'using **Google Colab** with **' + device if RunningInCOLAB else 'with **' + device}**.\n",
        "                    ''')\n",
        "        with gr.Accordion(\"Last update:\", open=False):\n",
        "          gr.Markdown('''\n",
        "                      05.01.24\n",
        "                      > The functionality of the '**Fine-tune model**' - '**Unconditional Diffusion Model**' tab is completely ready and tested.\n",
        "                      ''')\n",
        "\n",
        "        with gr.Accordion(\"Plans for future updates:\", open=False):\n",
        "          gr.Markdown('''\n",
        "                      > Completely complete the functionality of the '**Train model**' and '**Fine-tune model**' tabs\n",
        "                      ''')\n",
        "\n",
        "        with gr.Accordion(\"Author:\", open=False):\n",
        "          gr.Markdown('''\n",
        "                      Invented and implemented this project **Artsem Holub (WiNE-iNEFF)**.\n",
        "\n",
        "                      All my pages:\n",
        "                      <a href='https://huggingface.co/WiNE-iNEFF'>HuggingFace</a>,\n",
        "                      <a href='https://github.com/WiNE-iNEFF'>GitHub</a>,\n",
        "                      <a href='https://twitter.com/wine_ineff'>X (later Twitter)</a>.\n",
        "                      ''')\n",
        "\n",
        "\n",
        "      with gr.TabItem(\"Train model\"):\n",
        "        with gr.TabItem(\"Unconditional Diffusion Model\"):\n",
        "          future_update()\n",
        "        with gr.TabItem(\"Class-conditional Diffusion Model\"):\n",
        "          future_update()\n",
        "\n",
        "\n",
        "      with gr.TabItem(\"Fine-tune model\"):\n",
        "        with gr.TabItem(\"Unconditional Diffusion Model\"):\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "              huggingface_write_token = gr.Textbox(lines=1, label=\"Huggingface access token write permission (required)\", scale=2)\n",
        "              if RunningInCOLAB == True:\n",
        "                huggingface_secret_token = gr.Textbox(lines=1, label=\"Or write Huggingface 'secret name' from Google Colab\", scale=2)\n",
        "\n",
        "              hf_token = gr.Button(\"Login in HF\", size='sm', scale=1)\n",
        "              if RunningInCOLAB: hf_token.click(fn=hf_login, inputs=[huggingface_write_token, huggingface_secret_token], outputs=None)\n",
        "              else: hf_token.click(fn=hf_login, inputs=huggingface_write_token, outputs=None)\n",
        "\n",
        "            with gr.Accordion(\"Wandb setting (optional)\", open=False):\n",
        "              with gr.Row():\n",
        "                wandb_write_token = gr.Textbox(lines=1, label=\"WanDB api token (optional)\")\n",
        "                if RunningInCOLAB:\n",
        "                  wandb_secret_token = gr.Textbox(lines=1, label=\"Or write WanDB 'secret name' from Google Colab (optional)\")\n",
        "              with gr.Row():\n",
        "                wandb_project_name = gr.Textbox(lines=1, label=\"Project name\", placeholder='SimpleProject1')\n",
        "                wandb_run_name = gr.Textbox(lines=1, label=\"Run name\", placeholder='run 22.06.2001')\n",
        "\n",
        "              wandb_token = gr.Button(\"Login in WanDB\")\n",
        "              if RunningInCOLAB: wandb_token.click(fn=wandb_setup, inputs=[wandb_write_token, wandb_secret_token, wandb_project_name, wandb_run_name], outputs=None)\n",
        "              else: wandb_token.click(fn=wandb_setup, inputs=[wandb_write_token, wandb_project_name, wandb_run_name], outputs=None)\n",
        "\n",
        "            with gr.Accordion(\"Dataset setting (required)\", open=False):\n",
        "              with gr.Row():\n",
        "                pretrained_model = gr.Textbox(lines=1, label=\"Pretrained model from HuggingFace model library\", placeholder='WiNE-iNEFF/Minecraft-Skin-Diffusion-V2')\n",
        "                dataset_name = gr.Textbox(lines=1, label=\"Dataset link from HuggingFace dataset library\", placeholder='WiNE-iNEFF/kuvshinov_art_dataset')\n",
        "\n",
        "              with gr.Row():\n",
        "                image_size = gr.Textbox(lines=1, value=\"(64, 64)\", label=\"image size\", placeholder='(64, 64)')\n",
        "                batch_size = gr.Number(value=64, label=\"Batch size\", show_label=True, precision=0)\n",
        "                color_value = gr.Dropdown(choices=['RGBA', 'RGB'], value='RGB', label=\"Color value (RGBA/RGB). Must match the values with pretrained_model\")\n",
        "\n",
        "            with gr.Accordion(\"Train setting (required)\", open=False):\n",
        "              with gr.Row():\n",
        "                epoch = gr.Number(value=10, label=\"Number of train epoch\", show_label=True, precision=0)\n",
        "                grad_accumulation_steps = gr.Number(value=2, label=\"Gradient accumulation steps\", show_label=True, precision=0)\n",
        "              with gr.Row():\n",
        "                save_to_hub = gr.Number(value=1, label=\"How many epoch step need to save model checkpoint\", show_label=True, precision=0)\n",
        "                image_example = gr.Number(value=5, label=\"How many epoch step need to show image example (work only with wandb)\", show_label=True, precision=0)\n",
        "\n",
        "              model_name = gr.Textbox(lines=1, label=\"Model name to push in hub (required)\", placeholder='Minecraft-Skin-Diffusion-V2')\n",
        "              model_description = gr.Textbox(lines=3, label=\"Model description (optional)\")\n",
        "\n",
        "          finish_gallery = gr.Gallery()\n",
        "          start_btn = gr.Button(\"Start training\", variant='primary')\n",
        "\n",
        "          start_btn.click(fn=start_setup,\n",
        "                          inputs=[pretrained_model,\n",
        "                                  dataset_name,\n",
        "                                  image_size,\n",
        "                                  batch_size,\n",
        "                                  color_value,\n",
        "                                  epoch,\n",
        "                                  grad_accumulation_steps,\n",
        "                                  save_to_hub,\n",
        "                                  image_example,\n",
        "                                  model_name,\n",
        "                                  model_description],\n",
        "                          outputs=finish_gallery)\n",
        "\n",
        "        with gr.TabItem(\"Class-conditional Diffusion Model\"):\n",
        "          future_update()\n",
        "\n",
        "\n",
        "      with gr.TabItem(\"Test model\"):\n",
        "        future_update()\n",
        "\n",
        "demo.queue().launch(debug=True)"
      ],
      "metadata": {
        "id": "kDKYy1skkqln",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}